{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c0dcc4d",
   "metadata": {},
   "source": [
    "The dataset used to create the network can be found at [this](https://www.mimit.gov.it/index.php/it/open-data/elenco-dataset/carburanti-prezzi-praticati-e-anagrafica-degli-impianti) link\n",
    "\n",
    "In this case the data refer to the second trimester of 2025 so from the start of april to the end of june 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff69f6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c87d8ee",
   "metadata": {},
   "source": [
    "## Reading and cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5d299",
   "metadata": {},
   "source": [
    "Creating the data structure that contains all the attribute about the gas stations.\n",
    "\n",
    "**stations** = dict[station_id] -> (dict with station attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8c8933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "stations = {}\n",
    "\n",
    "with open(\"..//dataset//anagrafica_impianti_attivi.csv\", 'r', encoding=\"utf-8\") as data:\n",
    "\n",
    "    for line in csv.DictReader(data, delimiter=\";\"):\n",
    "        stations[line[\"idImpianto\"]] = line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd010016",
   "metadata": {},
   "source": [
    "Creating the data structure that contains for each day every price registered for that day.\n",
    "\n",
    "**prices** = dict[data] -> dict[index] -> (dict with single prices attribute)\n",
    "\n",
    ">For every day we could have different price for the same station this is because the same station can sell different type of fuel that have different price, like gasoline and diesel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9e59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "prices = {}\n",
    "\n",
    "# Start day for the dataset that contains the prices\n",
    "start_date = datetime.datetime(2025, 4, 1)\n",
    "actual_date = start_date\n",
    "\n",
    "# Last day for the dataset that contains the prices\n",
    "end_date = datetime.datetime(2025, 6, 30)\n",
    "\n",
    "\n",
    "while(actual_date <= end_date):\n",
    "\n",
    "    actual_date_str = actual_date.strftime(\"%Y%m%d\")\n",
    "    prices_actual_day = {}\n",
    "    index = 0\n",
    "\n",
    "    filename = \"..//dataset//fuel_prices//prezzo_alle_8-\" + actual_date_str + \".csv\"\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as data:\n",
    "\n",
    "        reader = csv.reader(data)\n",
    "        next(reader)\n",
    "\n",
    "        for line in csv.DictReader(data, delimiter=';'): \n",
    "            prices_actual_day[index] = line\n",
    "            index += 1\n",
    "    \n",
    "    prices[actual_date_str] = prices_actual_day\n",
    "\n",
    "    actual_date = actual_date + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10807f",
   "metadata": {},
   "source": [
    "Selecting only the station inside the region of **Lombardia** in Italy, as I don't want to analyze the data of the entire country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ad0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acronym for the provinces of Lombardy\n",
    "lombardia = (\"BG\",\"BS\",\"CO\",\"CR\",\"LC\",\"LO\",\"MN\",\"MI\",\"MB\",\"PV\",\"SO\",\"VA\")\n",
    "\n",
    "aux = {}\n",
    "\n",
    "for station in stations:\n",
    "    if stations[station][\"Provincia\"] in lombardia:\n",
    "        aux[station] = stations[station]\n",
    "\n",
    "stations_lombardia = aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a4354",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating the temporal networks with the same price, one for every fuel we are intereste to track."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e15cc8",
   "metadata": {},
   "source": [
    "**Node** = single station with the attribute.\n",
    "\n",
    ">Every node has several temporal timestamps (day), each timestamp refer to a price registered on a single day for a single type of fuel for a single station.\n",
    ">Example for the station 3456 we could have at the timestamp = n {Benzina:1,998, Diesel: 1,879}, Benzina stand for gasoline in the italian language.\n",
    ">Summing up, every node has a history of different price for different type of fuel.\n",
    "\n",
    "**Edge** = connection between two different station if they have at the same day, the same price, for the same fuel.\n",
    "\n",
    ">The edges are undirected, because if A is connected to B because they have the same price, B will be automacally connected with A.\n",
    ">Every edge has at least one timestamp, this represents the day when two different stations have the same price, if two stations have the same price for several days the edge will have several timestamps with the different price.\n",
    "\n",
    "It's important to say that raphtory can only manage directed networks, our network is undirected so in order to fix this issue I made a workaround.\n",
    "\n",
    "When i create an edge between two stations I have a list of element that are coupled togheter as an edge in this order, list[n] --> list[n+1] until the end of the list, where n is the index of an element inside the list.\n",
    "\n",
    "Given the edge source --> destination, the source and the destination are two different number representing the ids of the stations, they may not always be in the same position inside the list, so it could happend to have for one day the edge 12 --> 13 and for the next day the edge 13 --> 12, these are the same edge but not for raphtory, so in order to have always the same edges even on different days I order the list of ids that I use to create the edges, in this way I always have as source a id smaller than the destination.\n",
    "\n",
    "I am always sure to have 12 --> 13 even if the edge repeat on several different day.\n",
    "\n",
    "In this way for raphtory the edge are directed but we can treat them as non directed.\n",
    "\n",
    "You might wonder why I don't use a library that can handle undirected graphs, this is because raphtory is able to handle millions of edges using relatively little memory and taking little time, while also having many functions and being very versatile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243e163e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     61\u001b[39m                     network.add_edge(actual_date, station_ids[i], station_ids[j], properties={\u001b[33m\"\u001b[39m\u001b[33mprezzo\u001b[39m\u001b[33m\"\u001b[39m:price})\n\u001b[32m     62\u001b[39m                     \u001b[38;5;66;03m# network.add_edge(actual_date, prices_gasonline_id[price][j], prices_gasonline_id[price][i], properties={\"prezzo\":price})\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43mNetworkCreation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlombardia_stations_gasoline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGasolio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstations_lombardia\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m NetworkCreation(lombardia_stations_diesel, \u001b[33m\"\u001b[39m\u001b[33mBenzina\u001b[39m\u001b[33m\"\u001b[39m, stations_lombardia)         \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mNetworkCreation\u001b[39m\u001b[34m(network, fuel_type, stations_region)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(station_ids)):\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i+\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(station_ids)):\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m         \u001b[43mnetwork\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_edge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstation_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstation_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprezzo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprice\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import raphtory as rp\n",
    "\n",
    "lombardia_stations_gasoline = rp.Graph()\n",
    "lombardia_stations_diesel = rp.Graph()\n",
    "\n",
    "def NetworkCreation(network, fuel_type, stations_region):\n",
    "\n",
    "    new_stations = stations_region\n",
    "\n",
    "    # prices = dict[data] -> dict[index] -> (dict with single prices attribute)\n",
    "    for date in prices:\n",
    "\n",
    "        # prices_gasonline_id = dict(price) -> list(station_id)\n",
    "        prices_gasonline_id = {}\n",
    "\n",
    "        # index -> (dict with single prices attribute)\n",
    "        for index in prices[date]:\n",
    "\n",
    "            # Single price\n",
    "            price = prices[date][index]\n",
    "\n",
    "            # Check if the station is the list\n",
    "            # if the fuel type is the one we are looking for\n",
    "            # if the price is for self service fuel\n",
    "            if price[\"idImpianto\"] in new_stations and price[\"descCarburante\"] == fuel_type and price[\"isSelf\"] == '1':\n",
    "\n",
    "                if price[\"prezzo\"] not in prices_gasonline_id:\n",
    "                    prices_gasonline_id[price[\"prezzo\"]] = set()\n",
    "                \n",
    "                prices_gasonline_id[price[\"prezzo\"]].add(price[\"idImpianto\"])\n",
    "        \n",
    "        # Scroll the id of every station associated to the price\n",
    "        for price in prices_gasonline_id:\n",
    "\n",
    "            actual_date = datetime.datetime.strptime(date, \"%Y%m%d\")\n",
    "\n",
    "            for station_id in prices_gasonline_id[price]:\n",
    "\n",
    "                # Check if the station is already in the graph\n",
    "                # If not, add it to the graph with the price associated with the date (timestamp)\n",
    "                # and the properties of the station\n",
    "                # If yes, add the price associated with the date (timestamp)\n",
    "                try:\n",
    "                    if(network.has_node(station_id) == False):\n",
    "                        network.add_node(actual_date, id=station_id, properties={\"prezzo\":price})\n",
    "                        network.node(station_id).add_constant_properties(properties=stations[station_id])\n",
    "                    else:\n",
    "                        network.node(station_id).add_updates(actual_date, properties={\"prezzo\":price})\n",
    "\n",
    "                except Exception as error:\n",
    "                    print(\"Error\",station_id, error)\n",
    "                    pass\n",
    "            \n",
    "            station_ids = list(prices_gasonline_id[price])\n",
    "            station_ids.sort(key=int)\n",
    "\n",
    "            # Create the edges between the stations that have the same price\n",
    "            # adding the price as properties with the date (timestamp)\n",
    "            for i in range(0, len(station_ids)):\n",
    "                for j in range(i+1, len(station_ids)):\n",
    "                    network.add_edge(actual_date, station_ids[i], station_ids[j], properties={\"prezzo\":price})\n",
    "                    # network.add_edge(actual_date, prices_gasonline_id[price][j], prices_gasonline_id[price][i], properties={\"prezzo\":price})\n",
    "           \n",
    "\n",
    "NetworkCreation(lombardia_stations_gasoline, \"Gasolio\", stations_lombardia)\n",
    "NetworkCreation(lombardia_stations_diesel, \"Benzina\", stations_lombardia)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "lombardia_stations_gasoline.save_to_file(\"..//network//same_price//same_price_lombardia_stations_gasoline\")\n",
    "lombardia_stations_diesel.save_to_file(\"..//network//same_price//same_price_lombardia_stations_diesel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933f65d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Distance network creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b560d",
   "metadata": {},
   "source": [
    "Creating the map of the region we are interested in, to be able to calculate the space between stations, this operation could take several time, downloading or loading from cache an entire italian region is an heavy task and will fill up your RAM.\n",
    "\n",
    "The region is in the form of a graph wich every intersection is a node and every every nod is connected to those nearby by a edge.\n",
    "\n",
    "By using OSMnx I have to cite:\n",
    "\n",
    "Boeing, G. (2025). Modeling and Analyzing Urban Networks and Amenities with OSMnx. Geographical Analysis, published online ahead of print. doi:10.1111/gean.70009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541037cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: NX_CUGRAPH_AUTOCONFIG=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriele11231/.venvs/rapids25.06_python3.12/lib/python3.12/site-packages/osmnx/_overpass.py:267: UserWarning: This area is 14 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "%env NX_CUGRAPH_AUTOCONFIG=True\n",
    "import networkx as nx\n",
    "\n",
    "ox.settings.use_cache=True, \n",
    "ox.settings.log_console=True,\n",
    "ox.settings.max_quey_area_size = 875000000000\n",
    "\n",
    "lombardia_map = ox.graph_from_place('Lombardsko', network_type='drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf6689",
   "metadata": {},
   "source": [
    "Given the latitude and longitude of every station we are able to get the nearest node (intersection) in the map, this will be useful to get the real driving distances between every station in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def stations_to_map_nodes(region_stations, region_map):\n",
    "\n",
    "    stations_id = list(region_stations)\n",
    "\n",
    "    # Extract the longitudes and latitudes of the stations\n",
    "    # Convert them to numpy arrays for efficient processing\n",
    "    longitudes = np.array([float(stations[single_id]['Longitudine']) for single_id in stations_id])\n",
    "    latitudes = np.array([float(stations[single_id]['Latitudine']) for single_id in stations_id])\n",
    "\n",
    "    # Get the nearest nodes (intersection) in the map for each station\n",
    "    stations_nearest_nodes = ox.distance.nearest_nodes(region_map, longitudes, latitudes)\n",
    "\n",
    "    # Create a mapping from station ID to the nearest node ID\n",
    "    station_to_node = {}\n",
    "    for i in range(len(stations_id)):\n",
    "        station_to_node[stations_id[i]] = stations_nearest_nodes[i]\n",
    "    \n",
    "    return station_to_node\n",
    "\n",
    "station_to_node = stations_to_map_nodes(stations_lombardia, lombardia_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e23e4a1",
   "metadata": {},
   "source": [
    "Now after getting the nearest node (intersection) on the map for every station, we can calculate usign the dijkstra algorithm the shorthest path between every station.\n",
    "\n",
    "We are saving only the distances under 30km, this because we shouldn't find something useful in station that are far from each other more than 30km and also because we are saving a csv file containing all the distances and in this way the file will be much lighter.\n",
    "\n",
    "**WARNING**<br>\n",
    ">In order to compute the distance between every station we have tu run dijkstra a lot of times, this could require several computational time, to reduce the time needed to complete the entire script we are usign a Python library called cugraph that is able to use and Nvidia graphics card to complete some task, in particular it uses the cuda core of the card to run the algorithm, dijkstra in this case, this library only run on linux or windows WSL. <br>\n",
    "> To get more information about the library follow [this](https://rapids.ai/) link. \n",
    "\n",
    "\n",
    "Even with this trick running the entire script it took around 180 minutes on my machine that has the following components: <br>\n",
    "**CPU: Intel Ultra 7 265k, RAM: 32GB DDR5 6400MHz, GPU: Nvidia RTX 5070FE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7336a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_between_stations(station_to_node, region_map,region_name):\n",
    "\n",
    "    nx.config.warnings_to_ignore.add(\"cache\")\n",
    "    \n",
    "    stations_distances = []\n",
    "\n",
    "    index = 0\n",
    "    for i in station_to_node:\n",
    "\n",
    "        # Calculate the shortest path distances from the current station to all other stations\n",
    "        # using Dijkstra's algorithm with the 'length' attribute as the weight\n",
    "        # and using the cugraph backend for performance\n",
    "        # This will give us the distance in meters\n",
    "        distance = nx.single_source_dijkstra_path_length(region_map, station_to_node[i], weight=\"length\", backend=\"cugraph\")\n",
    "        for j in station_to_node:\n",
    "            \n",
    "            try:\n",
    "                if i != j and distance[station_to_node[j]]/1000 <= 30:\n",
    "\n",
    "                    # Append the distance in kilometers to the list\n",
    "                    # Only include distances less than or equal to 30 km\n",
    "                    # This is to avoid including very distant stations\n",
    "                    # in the dataset, as they are not relevant for the analysis\n",
    "                    stations_distances.append({\"Source\": i, \"Destination\": j, \"Distance\": distance[station_to_node[j]]/1000})\n",
    "\n",
    "            except KeyError:\n",
    "                pass\n",
    "        \n",
    "        index += 1\n",
    "        if index % 200 == 0:\n",
    "            print(\"Processed\", index, \"stations out of\", len(station_to_node))\n",
    "    \n",
    "    # Write the distances to a CSV file\n",
    "    fieldnames = [\"Source\", \"Destination\", \"Distance\"]\n",
    "    file_name = f\"../dataset/stations_distances_{region_name}.csv\"\n",
    "    with open(file_name, \"w\", newline=\"\") as file:\n",
    "\n",
    "        w = csv.DictWriter(file, fieldnames)\n",
    "        w.writeheader()\n",
    "\n",
    "        w.writerows(stations_distances)\n",
    "    \n",
    "    return stations_distances\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "region_name = \"Lombardia\"\n",
    "stations_distances = []\n",
    "\n",
    "# Check if the distances file already exists\n",
    "# If it does, read the distances from the file\n",
    "# If it does not, calculate the distances and save them to the file\n",
    "if(os.path.exists(f\"../dataset/stations_distances_{region_name}.csv\")):\n",
    "\n",
    "    with open(f\"../dataset/stations_distances_{region_name}.csv\", 'r', encoding=\"utf-8\") as data:\n",
    "\n",
    "        for line in csv.DictReader(data, delimiter=\",\"):\n",
    "            stations_distances.append({\"Source\": line[\"Source\"], \"Destination\": line[\"Destination\"], \"Distance\": float(line[\"Distance\"])})\n",
    "else:\n",
    "\n",
    "    stations_distances = distances_between_stations(station_to_node, lombardia_map, region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7cb55",
   "metadata": {},
   "source": [
    "Creating five different network, each one has a limit distance, the limit distances are 1,2,3,4,5.\n",
    "\n",
    "Every network have always the same nodes that they represent the stations.\n",
    "For the edges is differente, for example the network with limit distance 2 will have an edge connecting every node (stations) wich are separated by equal or less than 2km of driving distance, the same for the other network but with different km.\n",
    "\n",
    "We obtain five network with different connection distances, this will be useful during the analysis of the price behaviour in order to understand how far the price of fuel it propagates between stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_network(stations_distances, stations_region, region_name, distances):\n",
    "\n",
    "    distances_network = {}\n",
    "    # Create a network for each distance in the distances list\n",
    "    # Each network will contain the stations as nodes and the edges will be created based on the distances\n",
    "    for km in distances:\n",
    "        distances_network[km] = nx.Graph()\n",
    "        for station_id in stations_region:\n",
    "            distances_network[km].add_node(station_id, label=station_id, latitude=float(stations_region[station_id][\"Latitudine\"]), longitude=float(stations_region[station_id][\"Longitudine\"]))\n",
    "    \n",
    "    # Iterate through the distances and add edges to the network based on the distances\n",
    "    for distance in stations_distances:\n",
    "\n",
    "        source = distance[\"Source\"]\n",
    "        destination = distance[\"Destination\"]\n",
    "        stations_distance = distance[\"Distance\"]\n",
    "\n",
    "        for km in distances:\n",
    "            if stations_distance <= km:\n",
    "                distances_network[km].add_edge(source, destination)\n",
    "    \n",
    "    # Write the networks to GEXF files\n",
    "    for km in distances:\n",
    "        file_name = f\"../network/distance/{km}_km_distance_network_{region_name}.gexf\"\n",
    "        nx.write_gexf(distances_network[km], file_name)\n",
    "    \n",
    "    return distances_network\n",
    "\n",
    "distances_network = distance_network(stations_distances, stations_lombardia, region_name, [1,2,3,4,5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids25.06_python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
